"""
í‰ê°€ ë©”íŠ¸ë¦­ ìœ í‹¸ë¦¬í‹° (Macro F1 Score ì‚¬ìš©)
"""
from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, classification_report, confusion_matrix
from typing import Dict
import numpy as np
import torch


def calculate_metrics(y_true: np.ndarray, y_pred: np.ndarray) -> Dict:
    """
    ë¶„ë¥˜ ë©”íŠ¸ë¦­ ê³„ì‚° (Macro F1 Score ì‚¬ìš©)

    Args:
        y_true: ì‹¤ì œ ë¼ë²¨ (0=Real, 1=Fake)
        y_pred: ì˜ˆì¸¡ ë¼ë²¨

    Returns:
        ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
    """
    # Macro F1 Score (ëŒ€íšŒ í‰ê°€ ê¸°ì¤€)
    macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)

    # ì¶”ê°€ ë©”íŠ¸ë¦­
    accuracy = accuracy_score(y_true, y_pred)

    # í´ë˜ìŠ¤ë³„ F1 Score
    f1_per_class = f1_score(y_true, y_pred, average=None, zero_division=0)
    f1_real = f1_per_class[0] if len(f1_per_class) > 0 else 0.0
    f1_fake = f1_per_class[1] if len(f1_per_class) > 1 else 0.0

    # Precision, Recall
    precision_macro = precision_score(
        y_true, y_pred, average='macro', zero_division=0)
    recall_macro = recall_score(
        y_true, y_pred, average='macro', zero_division=0)

    # Confusion Matrix
    cm = confusion_matrix(y_true, y_pred)
    tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)

    return {
        'macro_f1': float(macro_f1),  # ëŒ€íšŒ í‰ê°€ ê¸°ì¤€
        'f1_score': float(macro_f1),  # í˜¸í™˜ì„±
        'f1_real': float(f1_real),
        'f1_fake': float(f1_fake),
        'accuracy': float(accuracy),
        'precision': float(precision_macro),
        'recall': float(recall_macro),
        'confusion_matrix': {
            'tn': int(tn),
            'fp': int(fp),
            'fn': int(fn),
            'tp': int(tp)
        }
    }


def print_classification_report(y_true: np.ndarray, y_pred: np.ndarray):
    """
    ë¶„ë¥˜ ë¦¬í¬íŠ¸ ì¶œë ¥

    Args:
        y_true: ì‹¤ì œ ë¼ë²¨
        y_pred: ì˜ˆì¸¡ ë¼ë²¨
    """
    print("\n" + "="*50)
    print("Classification Report")
    print("="*50)
    print(classification_report(y_true, y_pred, target_names=['Real', 'Fake']))
    print("="*50)

    # Macro F1 Score ê°•ì¡°
    macro_f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)
    print(f"\nğŸŒŸ Macro F1 Score (ëŒ€íšŒ í‰ê°€ ê¸°ì¤€): {macro_f1:.4f}")
    print("="*50 + "\n")
